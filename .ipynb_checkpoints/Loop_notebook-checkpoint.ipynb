{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c565d3c6-0ca7-4d95-ad6f-457f27937779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting splinter\n",
      "  Downloading splinter-0.21.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: urllib3<3.0,>=1.26.14 in /Applications/anaconda3/lib/python3.12/site-packages (from splinter) (2.2.3)\n",
      "Downloading splinter-0.21.0-py3-none-any.whl (40 kB)\n",
      "Installing collected packages: splinter\n",
      "Successfully installed splinter-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install splinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69214600-eb8c-4339-84cc-a985d644d6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in /Applications/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /Applications/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in /Applications/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/lib/python3.12/site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.12/site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/lib/python3.12/site-packages (from requests->webdriver-manager) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.12/site-packages (from requests->webdriver-manager) (2024.8.30)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver-manager\n",
      "Successfully installed webdriver-manager-4.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d25dbd-0b72-46cf-8ef0-fcf37bd3bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd9a60-6e12-4290-8ba4-72c4c16513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "urls ={0:\"https://www.metacritic.com/browse/game/all/adventure/all-time/metascore/?releaseYearMin=1991&releaseYearMax=2011&genre=adventure&page=1\",\n",
    "       1:\"https://www.metacritic.com/browse/game/all/adventure/all-time/metascore/?releaseYearMin=1991&releaseYearMax=2011&genre=adventure&page=2\",\n",
    "       2:\"https://www.metacritic.com/browse/game/all/adventure/all-time/metascore/?releaseYearMin=1991&releaseYearMax=2011&genre=adventure&page=3\",\n",
    "       3:\"https://www.metacritic.com/browse/game/all/adventure/all-time/metascore/?releaseYearMin=1991&releaseYearMax=2011&genre=adventure&page=4\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844923f-8014-4ab9-92bf-8ce7553a16af",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "browser.visit(urls[0])\n",
    "    \n",
    "for url in urls.values():\n",
    "    \n",
    "    html = browser.html\n",
    "    \n",
    "    dfs = pd.read_html(html)\n",
    "    if len(dfs)>0:\n",
    "        \n",
    "        main_df=main_df.append(dfs[0])\n",
    "    \n",
    "    counter+=1\n",
    "    \n",
    "    try:\n",
    "        browser.click_link_by_href(urls[counter]) \n",
    "    except:\n",
    "            try:\n",
    "                \n",
    "                browser.click_link_by_text('arrowChevron') \n",
    "            except:\n",
    "                print(\"Found last page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4498f22e-6360-47cd-94b4-3b20b84207f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up headless Chrome browser\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Change to False to see the browser\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Loop through pages 1 to 4\n",
    "all_games = []\n",
    "\n",
    "for page in range(1, 5):\n",
    "    url = f\"https://www.metacritic.com/browse/game/all/adventure/all-time/metascore/?releaseYearMin=1991&releaseYearMax=2011&genre=adventure&page={page}\"\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Wait for JS to load\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    titles = soup.find_all('div','c-finderProductCard_title')\n",
    "    \n",
    "    titles_a = []\n",
    "\n",
    "    for htag in titles:\n",
    "        title = htag.find_all(\"span\")[1].text.strip()\n",
    "        titles_a.append(title)\n",
    "\n",
    "    dates = soup.find_all('div','c-finderProductCard_meta')\n",
    "\n",
    "    dates_a = []\n",
    "\n",
    "    for date in dates:\n",
    "        span = date.find('span', class_='u-text-uppercase')\n",
    "        if span:  # check if span was found\n",
    "            i = span.text.strip()\n",
    "            dates_a.append(i)\n",
    "        else:\n",
    "            dates_a.append(None)  # or skip with `continue`\n",
    "            \n",
    "    clean_list = [x for x in dates_a if x is not None]\n",
    "\n",
    "    rates = soup.find_all('div','c-finderProductCard_meta')\n",
    "\n",
    "    rates_a = []\n",
    "\n",
    "    for rate in rates:\n",
    "        span = rate.find('span', class_='u-text-capitalize')\n",
    "        #rating_value = rating_span.next_sibling.strip()\n",
    "        if span:  # check if span was found\n",
    "            i = span.next_sibling.strip()\n",
    "            rates_a.append(i)\n",
    "        else:\n",
    "            rates_a.append(None)  # or skip with `continue`\n",
    "            \n",
    "    clean_list_2 = [x for x in rates_a if x is not None]\n",
    "\n",
    "    descriptions = soup.find_all('div','c-finderProductCard_description')\n",
    "\n",
    "    descriptions_a = []\n",
    "\n",
    "    for description in descriptions:\n",
    "        description_span = description.find('span')\n",
    "        description_value = description_span.text.strip() if description_span else None\n",
    "        descriptions_a.append(description_value)\n",
    "\n",
    "    scores = soup.find_all('div','c-siteReviewScore')\n",
    "\n",
    "    scores_a = []\n",
    "\n",
    "    for score in scores:\n",
    "        metascore_text = score.get(\"aria-label\")\n",
    "        scores_a.append(metascore_text)\n",
    "\n",
    "    # Example lists\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Title': titles_a,\n",
    "        'Date': clean_list,\n",
    "        'Rating': clean_list_2,\n",
    "        'Description': descriptions_a,\n",
    "        'score': scores_a\n",
    "    })\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    df_list.append(df) \n",
    "\n",
    "\n",
    "    \n",
    "    # Combine all DataFrames at once\n",
    "    final_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "# Show results\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33f05f26-fa64-464b-9dac-19db07ad32c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"c-finderProductCard_title\" data-title=\"CSI: Crime Scene Investigation: Deadly Intent\"><h3 class=\"c-finderProductCard_titleHeading\"><span>73.</span> <span>CSI: Crime Scene Investigation: Deadly Intent</span></h3></div>,\n",
       " <div class=\"c-finderProductCard_title\" data-title=\"Dead Reefs\"><h3 class=\"c-finderProductCard_titleHeading\"><span>74.</span> <span>Dead Reefs</span></h3></div>,\n",
       " <div class=\"c-finderProductCard_title\" data-title=\"Code Lyoko: Fall of X.A.N.A.\"><h3 class=\"c-finderProductCard_titleHeading\"><span>75.</span> <span>Code Lyoko: Fall of X.A.N.A.</span></h3></div>,\n",
       " <div class=\"c-finderProductCard_title\" data-title=\"Mystery of the Druids\"><h3 class=\"c-finderProductCard_titleHeading\"><span>76.</span> <span>Mystery of the Druids</span></h3></div>,\n",
       " <div class=\"c-finderProductCard_title\" data-title=\"Jake Hunter: Detective Chronicles\"><h3 class=\"c-finderProductCard_titleHeading\"><span>77.</span> <span>Jake Hunter: Detective Chronicles</span></h3></div>,\n",
       " <div class=\"c-finderProductCard_title\" data-title=\"Coraline\"><h3 class=\"c-finderProductCard_titleHeading\"><span>78.</span> <span>Coraline</span></h3></div>,\n",
       " <div class=\"c-finderProductCard_title\" data-title=\"CSI: Crime Scene Investigation: Fatal Conspiracy\"><h3 class=\"c-finderProductCard_titleHeading\"><span>79.</span> <span>CSI: Crime Scene Investigation: Fatal Conspiracy</span></h3></div>,\n",
       " <div class=\"c-finderProductCard_title\" data-title=\"Prison Break: The Conspiracy\"><h3 class=\"c-finderProductCard_titleHeading\"><span>80.</span> <span>Prison Break: The Conspiracy</span></h3></div>,\n",
       " <div class=\"c-finderProductCard_title\" data-title=\"Inkheart\"><h3 class=\"c-finderProductCard_titleHeading\"><span>81.</span> <span>Inkheart</span></h3></div>,\n",
       " <div class=\"c-finderProductCard_title\" data-title=\"NCIS\"><h3 class=\"c-finderProductCard_titleHeading\"><span>82.</span> <span>NCIS</span></h3></div>,\n",
       " <div class=\"c-finderProductCard_title\" data-title=\"Survivor (2001)\"><h3 class=\"c-finderProductCard_titleHeading\"><span>83.</span> <span>Survivor (2001)</span></h3></div>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = soup.find_all('div','c-finderProductCard_title')\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e974bb8f-e159-411a-8db4-6e950f3ee0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m     scores_a \u001b[38;5;241m=\u001b[39m [score\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maria-label\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m scores]\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Create DataFrame and append to list\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m: titles_a,\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m: dates_a,\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m'\u001b[39m: rates_a,\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m: descriptions_a,\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m'\u001b[39m: scores_a\n\u001b[1;32m     53\u001b[0m     })\n\u001b[1;32m     55\u001b[0m     df_list\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Close browser after all pages are scraped\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up headless Chrome browser\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Change to False to see the browser\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Collect all DataFrames here\n",
    "df_list = []\n",
    "\n",
    "for page in range(1, 5):\n",
    "    url = f\"https://www.metacritic.com/browse/game/all/adventure/all-time/metascore/?releaseYearMin=1991&releaseYearMax=2011&genre=adventure&page={page}\"\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Wait for JS to load\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    titles = soup.find_all('div', class_='c-finderProductCard_title')\n",
    "    titles_a = [t.find_all(\"span\")[1].text.strip() for t in titles if len(t.find_all(\"span\")) > 1]\n",
    "\n",
    "    dates = soup.find_all('div', class_='c-finderProductCard_meta')\n",
    "    dates_a = []\n",
    "    rates_a = []\n",
    "\n",
    "    for d in dates:\n",
    "        span_date = d.find('span', class_='u-text-uppercase')\n",
    "        dates_a.append(span_date.text.strip() if span_date else None)\n",
    "\n",
    "        span_rating = d.find('span', class_='u-text-capitalize')\n",
    "        rates_a.append(span_rating.next_sibling.strip() if span_rating and span_rating.next_sibling else None)\n",
    "\n",
    "    descriptions = soup.find_all('div', class_='c-finderProductCard_description')\n",
    "    descriptions_a = [desc.find('span').text.strip() if desc.find('span') else None for desc in descriptions]\n",
    "\n",
    "    scores = soup.find_all('div', class_='c-siteReviewScore')\n",
    "    scores_a = [score.get(\"aria-label\") for score in scores]\n",
    "\n",
    "    # Create DataFrame and append to list\n",
    "    df = pd.DataFrame({\n",
    "        'Title': titles_a,\n",
    "        'Date': dates_a,\n",
    "        'Rating': rates_a,\n",
    "        'Description': descriptions_a,\n",
    "        'Score': scores_a\n",
    "    })\n",
    "\n",
    "    df_list.append(df)\n",
    "\n",
    "# Close browser after all pages are scraped\n",
    "driver.quit()\n",
    "\n",
    "# Combine all pages into one DataFrame\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Display result\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92a1d7d-1df9-4e6a-a278-9b4e7ef6be5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Titles: 24, Dates: 48, Ratings: 48, Descriptions: 24, Scores: 24\n",
      "Scraping page 2...\n",
      "Titles: 24, Dates: 48, Ratings: 48, Descriptions: 24, Scores: 24\n",
      "Scraping page 3...\n",
      "Titles: 24, Dates: 48, Ratings: 48, Descriptions: 24, Scores: 24\n",
      "Scraping page 4...\n",
      "Titles: 11, Dates: 22, Ratings: 22, Descriptions: 11, Scores: 11\n",
      "                                       Title          Date Rating  \\\n",
      "0  Zack & Wiki: Quest for Barbaros' Treasure  Oct 23, 2007      E   \n",
      "1                                     flower          None   None   \n",
      "2             Ghost Trick: Phantom Detective  Feb 12, 2009      E   \n",
      "3                The Book of Unwritten Tales          None   None   \n",
      "4                   Prince of Persia Classic  Jan 11, 2011      T   \n",
      "\n",
      "                                         Description                    Score  \n",
      "0  Legend has it that a revered pirate named Barb...  Metascore 87 out of 100  \n",
      "1  [Playstation Network]  The pioneers that broug...  Metascore 87 out of 100  \n",
      "2  Ghost Trick is a story of mystery and intrigue...  Metascore 83 out of 100  \n",
      "3  In a world torn by war, the aged gremlin archa...  Metascore 82 out of 100  \n",
      "4  [Xbox Live Arcade]  While the Sultan of Persia...  Metascore 82 out of 100  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up headless Chrome browser\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Set to False to see browser in action\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# List to store all DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop through pages 1 to 4\n",
    "for page in range(1, 5):\n",
    "    url = f\"https://www.metacritic.com/browse/game/all/adventure/all-time/metascore/?releaseYearMin=1991&releaseYearMax=2011&genre=adventure&page={page}\"\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Wait for JavaScript to load\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Extract titles\n",
    "    titles = soup.find_all('div', class_='c-finderProductCard_title')\n",
    "    titles_a = [t.find_all(\"span\")[1].text.strip() for t in titles if len(t.find_all(\"span\")) > 1]\n",
    "\n",
    "    # Extract dates and ratings\n",
    "    dates = soup.find_all('div', class_='c-finderProductCard_meta')\n",
    "    dates_a = []\n",
    "    rates_a = []\n",
    "\n",
    "    for d in dates:\n",
    "        span_date = d.find('span', class_='u-text-uppercase')\n",
    "        dates_a.append(span_date.text.strip() if span_date else None)\n",
    "\n",
    "        span_rating = d.find('span', class_='u-text-capitalize')\n",
    "        rates_a.append(span_rating.next_sibling.strip() if span_rating and span_rating.next_sibling else None)\n",
    "\n",
    "    # Extract descriptions\n",
    "    descriptions = soup.find_all('div', class_='c-finderProductCard_description')\n",
    "    descriptions_a = [desc.find('span').text.strip() if desc.find('span') else None for desc in descriptions]\n",
    "\n",
    "    # Extract scores\n",
    "    scores = soup.find_all('div', class_='c-siteReviewScore')\n",
    "    scores_a = [score.get(\"aria-label\") for score in scores]\n",
    "\n",
    "    # Debugging: check list lengths\n",
    "    print(f\"Titles: {len(titles_a)}, Dates: {len(dates_a)}, Ratings: {len(rates_a)}, Descriptions: {len(descriptions_a)}, Scores: {len(scores_a)}\")\n",
    "\n",
    "    # Trim to shortest length\n",
    "    min_len = min(len(titles_a), len(dates_a), len(rates_a), len(descriptions_a), len(scores_a))\n",
    "\n",
    "    data = zip(\n",
    "        titles_a[:min_len],\n",
    "        dates_a[:min_len],\n",
    "        rates_a[:min_len],\n",
    "        descriptions_a[:min_len],\n",
    "        scores_a[:min_len]\n",
    "    )\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=['Title', 'Date', 'Rating', 'Description', 'Score'])\n",
    "    df_list.append(df)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Combine all data into one DataFrame\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc600195-edcd-406e-bdd5-b35eaa16496e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zack &amp; Wiki: Quest for Barbaros' Treasure</td>\n",
       "      <td>Oct 23, 2007</td>\n",
       "      <td>E</td>\n",
       "      <td>Legend has it that a revered pirate named Barb...</td>\n",
       "      <td>Metascore 87 out of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flower</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Playstation Network]  The pioneers that broug...</td>\n",
       "      <td>Metascore 87 out of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ghost Trick: Phantom Detective</td>\n",
       "      <td>Feb 12, 2009</td>\n",
       "      <td>E</td>\n",
       "      <td>Ghost Trick is a story of mystery and intrigue...</td>\n",
       "      <td>Metascore 83 out of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Book of Unwritten Tales</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>In a world torn by war, the aged gremlin archa...</td>\n",
       "      <td>Metascore 82 out of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prince of Persia Classic</td>\n",
       "      <td>Jan 11, 2011</td>\n",
       "      <td>T</td>\n",
       "      <td>[Xbox Live Arcade]  While the Sultan of Persia...</td>\n",
       "      <td>Metascore 82 out of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>CSI: Crime Scene Investigation: Fatal Conspiracy</td>\n",
       "      <td>Dec 31, 2001</td>\n",
       "      <td>M</td>\n",
       "      <td>CSI: Fatal Conspiracy features five new connec...</td>\n",
       "      <td>Metascore 42 out of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Prison Break: The Conspiracy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Prison Break - The Conspiracy takes you inside...</td>\n",
       "      <td>Metascore 40 out of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Inkheart</td>\n",
       "      <td>Jun 11, 2008</td>\n",
       "      <td>T</td>\n",
       "      <td>Based on the feature film adaptation of the be...</td>\n",
       "      <td>Metascore 39 out of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>NCIS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NCIS is now available for the first time ever ...</td>\n",
       "      <td>Metascore 35 out of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Survivor (2001)</td>\n",
       "      <td>Jan 27, 2009</td>\n",
       "      <td>E10+</td>\n",
       "      <td>Play as any of the actual Pulau Tiga and Austr...</td>\n",
       "      <td>Metascore 26 out of 100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title          Date Rating  \\\n",
       "0          Zack & Wiki: Quest for Barbaros' Treasure  Oct 23, 2007      E   \n",
       "1                                             flower          None   None   \n",
       "2                     Ghost Trick: Phantom Detective  Feb 12, 2009      E   \n",
       "3                        The Book of Unwritten Tales          None   None   \n",
       "4                           Prince of Persia Classic  Jan 11, 2011      T   \n",
       "..                                               ...           ...    ...   \n",
       "78  CSI: Crime Scene Investigation: Fatal Conspiracy  Dec 31, 2001      M   \n",
       "79                      Prison Break: The Conspiracy          None   None   \n",
       "80                                          Inkheart  Jun 11, 2008      T   \n",
       "81                                              NCIS          None   None   \n",
       "82                                   Survivor (2001)  Jan 27, 2009   E10+   \n",
       "\n",
       "                                          Description                    Score  \n",
       "0   Legend has it that a revered pirate named Barb...  Metascore 87 out of 100  \n",
       "1   [Playstation Network]  The pioneers that broug...  Metascore 87 out of 100  \n",
       "2   Ghost Trick is a story of mystery and intrigue...  Metascore 83 out of 100  \n",
       "3   In a world torn by war, the aged gremlin archa...  Metascore 82 out of 100  \n",
       "4   [Xbox Live Arcade]  While the Sultan of Persia...  Metascore 82 out of 100  \n",
       "..                                                ...                      ...  \n",
       "78  CSI: Fatal Conspiracy features five new connec...  Metascore 42 out of 100  \n",
       "79  Prison Break - The Conspiracy takes you inside...  Metascore 40 out of 100  \n",
       "80  Based on the feature film adaptation of the be...  Metascore 39 out of 100  \n",
       "81  NCIS is now available for the first time ever ...  Metascore 35 out of 100  \n",
       "82  Play as any of the actual Pulau Tiga and Austr...  Metascore 26 out of 100  \n",
       "\n",
       "[83 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
